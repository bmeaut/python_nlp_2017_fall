{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 8. Morphology — Lab exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## XFST / foma\n",
    "\n",
    "XFST provides two formalisms for creating FSA / FST for morphology and related fields:\n",
    "- _regular expressions_: similar to Python's (e.g. `{reg}?*({expr})` $\\equiv$ `reg.*(expr)?`)\n",
    "- _lexc_: a much simpler formalism for lexicographers\n",
    "\n",
    "In this lab, we shall learn the latter via the open-source reimplementation of XFST: foma. We shall also acquaint ourselves with the Hungarian HFST morphology. We are not going into details of how foma works; for that, see the\n",
    "- https://fomafst.github.io/\n",
    "- https://github.com/mhulden/foma/\n",
    "- the XFST book (Kenneth R. Beesley and Lauri Karttunen: [Finite State Morphology](https://web.stanford.edu/~laurik/fsmbook/home.html))\n",
    "\n",
    "But first..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Command-line access from Python\n",
    "\n",
    "In some cases, we need to interface with command-line applications from our script. There are two ways to do this in Python, and an additional method in Jupyter.\n",
    "\n",
    "### 1. `os.system()`\n",
    "\n",
    "The `os.system(cmd)` call executes `cmd`, sends its output to the `stdout` of the interpreter, and returns the exit code of the process. As such, there is no way to capture the output in the script, so this method is only useful if we are interested solely in the exit code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Note that the actual output of `ls` is not printed!\n",
    "print('Exit code:', os.system('ls -a'))\n",
    "files = os.listdir('.')\n",
    "print('Should have printed:\\n\\n{}'.format('\\n'.join(files if len(files) <= 3 else files[:3] + ['...'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. subprocess\n",
    "\n",
    "The [`subprocess`](https://docs.python.org/3/library/subprocess.html) module provides full access to the command line. The basic method of usage is to create a `Popen` object and call its methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "p = subprocess.Popen(['ls', '-a'],            # manual cmd split; see next example\n",
    "                     stdout=subprocess.PIPE)  # we need the output\n",
    "ret = p.communicate()\n",
    "print('Exit code: {}\\nOutput:\\n\\n{}'.format(p.returncode, ret[0].decode('utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It is also possible to send input to a program started by `Popen`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "p = subprocess.Popen('cat -', shell=True,    # automatic cmd split -> ['cat', '-']\n",
    "                     stdin=subprocess.PIPE,  # we shall use stdin\n",
    "                     stdout=subprocess.PIPE)\n",
    "ret = p.communicate('hello\\nbello'.encode('utf-8'))\n",
    "print(ret[0].decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "From Python 3.6, `Popen` supports the `encoding` parameter, which alleviates the need for `encode`/`decode`.\n",
    "\n",
    "There are also functions that cover the basic cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# From Python 3.5\n",
    "ret = subprocess.run('ls -a', shell=True, stdout=subprocess.PIPE)\n",
    "print('run():\\n{}'.format(\n",
    "    ret.stdout.decode('utf-8')))\n",
    "# Even easier\n",
    "print('check_output()\\n{}'.format(\n",
    "    subprocess.check_output('ls -a', shell=True).decode('utf-8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3. Jupyter!\n",
    "\n",
    "Jupyter also has a shorthand for executing commands: `!`. It is a bit more convenient, as it does string encoding behind the scenes and parses the output into a list. However, it is not available in regular Python scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "directory = '.'\n",
    "s = !ls -a {directory}\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Morphology\n",
    "\n",
    "Take a few minutes to make yourself familiar with the code below. It defines the functions we use to communicate with foma via the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "from functools import partial\n",
    "import os\n",
    "import subprocess\n",
    "import tempfile\n",
    "\n",
    "from IPython.display import display, Image\n",
    "\n",
    "def execute_commands(*cmds, fancy=True):\n",
    "    \"\"\"\n",
    "    Starts foma end executes the specified commands.\n",
    "    Might not work if there are too many...\n",
    "    \"\"\"\n",
    "    if fancy:\n",
    "        print('Executing commands...\\n=====================\\n')\n",
    "    args = ' '.join('-e \"{}\"'.format(cmd) for cmd in cmds)\n",
    "    output = subprocess.check_output('foma {} -s'.format(args),\n",
    "                                     stderr=subprocess.STDOUT,\n",
    "                                     shell=True).decode('utf-8')\n",
    "    print(output)\n",
    "    if fancy:\n",
    "        print('=====================\\n')\n",
    "    \n",
    "def compile_lexc(lexc_string, fst_file):\n",
    "    \"\"\"\n",
    "    Compiles a string describing a lexc lexicon with foma. The FST\n",
    "    is written to fst_file.\n",
    "    \"\"\"\n",
    "    with tempfile.NamedTemporaryFile(mode='wt', encoding='utf-8', delete=False) as outf:\n",
    "            outf.write(lexc_string)\n",
    "    try:\n",
    "        execute_commands('read lexc {}'.format(outf.name),\n",
    "                         'save stack {}'.format(fst_file), fancy=False)\n",
    "        #!foma -e \"read lexc {outf.name}\" -e \"save stack {fst_file}\" -s\n",
    "    finally:\n",
    "        os.remove(outf.name)\n",
    "        \n",
    "def apply(fst_file, words, up=True):\n",
    "    \"\"\"\n",
    "    Applies the FST in fst_file on the supplied words. The default direction\n",
    "    is up.\n",
    "    \"\"\"\n",
    "    if isinstance(words, list):\n",
    "        words = '\\n'.join(map(str, words))\n",
    "    elif not isinstance(words, str):\n",
    "        raise ValueError('words must be a str or list')\n",
    "    header = 'Applying {} {}...'.format(fst_file, 'up' if up else 'down')\n",
    "    print('{}\\n{}\\n'.format(header, '=' * len(header)))\n",
    "    invert = '-i' if not up else ''\n",
    "    result = subprocess.check_output('flookup {} {}'.format(invert, fst_file),\n",
    "                                     stderr=subprocess.STDOUT, shell=True,\n",
    "                                     input=words.encode('utf-8'))\n",
    "    print(result.decode('utf-8')[:-1])  # Skip last newline\n",
    "    print('=' * len(header), '\\n')\n",
    "       \n",
    "apply_up = partial(apply, up=True)\n",
    "apply_down = partial(apply, up=False)\n",
    "\n",
    "def draw_net(fst_file, inline=True):\n",
    "    \"\"\"\n",
    "    Displays a compiled network inline or in a separate window.\n",
    "    The package imagemagic must be installed for this function to work.\n",
    "    \"\"\"\n",
    "    !foma -e \"load stack {fst_file}\" -e \"print dot >{fst_file}.dot\" -s\n",
    "    if inline:\n",
    "        png_data = subprocess.check_output(\n",
    "            'cat {}.dot | dot -Tpng'.format(fst_file), shell=True)\n",
    "        display(Image(data=png_data, format='png'))\n",
    "    else:\n",
    "        !cat {fst_file}.dot | dot -Tpng | display\n",
    "    !rm {fst_file}.dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Warm-up\n",
    "\n",
    "First a few warm-up exercises. This will teach you how to use the functions defined above and give you a general idea of how a lexical transducer looks like. We shall cover a tiny subset of the English verb morphology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Task W1.\n",
    "\n",
    "A _lexc_ grammar consists of `LEXICON`s, which corresponds to continuation classes. One lexicon, `Root` must always be present. Let's add the two words _pack_ and _talk_ to it. We shall build the grammar in a Python string and use the `compile_lexc()` function to compile it to binary format, and `draw_net()` to display the resulting automaton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "grammar = \"\"\"\n",
    "LEXICON Root\n",
    "pack # ;\n",
    "talk # ;\n",
    "walk # ;\n",
    "\"\"\"\n",
    "\n",
    "compile_lexc(grammar, 'warm_up.fst')\n",
    "draw_net('warm_up.fst')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "There are several points to observe here:\n",
    "- the format of a word (morpheme) definition line is: `morpheme next_lexicon ;`\n",
    "    - the `next_lexicon` can be the word end mark `#`\n",
    "    - word definitions _must_ end with a semicolon (`;`); `LEXICON` lines _must not_\n",
    "- the basic unit in the FSA is the character, not the whole word\n",
    "- the FSA is _determinized_ and _minimized_ to save space: see how the states **(3)** and **(5)** and the arc **-k->** are re-used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Task W2.\n",
    "\n",
    "Let's add some inflection to the grammar. These are all regular verbs, so they all can receive _-s_, _-ed_, and _-ing_ to form the third person singular, past and gerund forms, respectively. Add these to the second lexicon, and\n",
    "compile the network again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "grammar = \"\"\"\n",
    "LEXICON Root\n",
    "! see how the continuation changes to the new LEXICON\n",
    "! BTW this is a comment\n",
    "pack Infl ;\n",
    "talk Infl ;\n",
    "walk Infl ;\n",
    "\n",
    "LEXICON Infl\n",
    "! add the endings here, without the hyphens\n",
    "\"\"\"\n",
    "\n",
    "compile_lexc(grammar, 'warm_up.fst')\n",
    "draw_net('warm_up.fst')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, we can test what words the automaton can recognize in two ways:\n",
    "- call the `apply_up` or `apply_down` functions with the word form\n",
    "- use the `print words` foma command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "apply_up('warm_up.fst', ['walked', 'talking', 'packs', 'walk'])\n",
    "execute_commands('load stack warm_up.fst', 'print words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Uh-oh. Something's wrong: the automaton didn't recognize _walk_. What happened?\n",
    "\n",
    "The explanation is very simple: now all words in `Root` continue to `Infl`, which requires one of the inflectional endings. See how state **(6)** ceased to be an accepting state.\n",
    "\n",
    "The solution: replicate the code from [above](#Task-W2.), but also add the \"zero morpheme\" ending `    # ;` to `Infl`! Make sure that state **(6)** is accepting again and that the recognized words now include the basic form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Task W3.\n",
    "\n",
    "Here we change our automaton to a transducer that lemmatizes words it receives on its bottom tape. Transduction in _lexc_ is denoted by the colon (`:`). Again, copy your grammar below, but replace the contents of `LEXICON Infl` with\n",
    "```\n",
    "      # ;\n",
    "0:s   # ;\n",
    "0:ed  # ;\n",
    "0:ing # ;\n",
    "```\n",
    "Note that\n",
    "- only a single colon is allowed on a line\n",
    "- everything left of it is \"up\", right is \"down\"\n",
    "- the $\\varepsilon$ (empty character) is denoted by `0`\n",
    "- deletion happens on the top, \"output\" side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "grammar = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "compile_lexc(grammar, 'warm_up.fst')\n",
    "draw_net('warm_up.fst')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Experiment again with `apply_up` and `apply_down`. How do they behave differently?\n",
    "\n",
    "See how the output of the `print words` command changed. It is also useful to print just the upper or lower tape with `print upper-words` and `print lower-words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# apply_up('warm_up.fst', ['walked', 'talking', 'packs', 'walk'])\n",
    "# execute_commands('load stack warm_up.fst', 'print words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Lexc Intuition\n",
    "\n",
    "While the ideas behind lexc are very logical, one might need some time to wrap their heads around it. [In this notebook](09_Lexc_Intuition.ipynb), I try to provide some intuition / advice on how to \"think lexc\". Do not hesitate to check it out if the tasks below seem to hard. I also provide the solution to [task H1](#Task-H1.) in there, though you are encouraged to come up with your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Hungarian Adjectives\n",
    "\n",
    "In this exercise, we shall model a subset of the Hungarian nominal paradigm:\n",
    "- regular adjectives\n",
    "- vowel harmony\n",
    "- plurals\n",
    "- the accusative case\n",
    "- comparative and superlative forms\n",
    "\n",
    "The goal is to replicate the output of the Hungarian HFST morphology. We shall learn the following techniques:\n",
    "- defining lexical automata and tranducers with lexc\n",
    "- multi-character symbols\n",
    "- flag diacritics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Task H1.\n",
    "\n",
    "We start small with a tiny lexical FSA.\n",
    "- define a `LEXICON` for the adjectives in the code cell below\n",
    "- add continuation classes to handle:\n",
    "  - the plural form (_-ek_)\n",
    "  - accusative (_-et_)\n",
    "  \n",
    "A little help for the latter two: in Hungarian, adjectives (and numerals) are inflected the same way as nouns; this is called the _nominal paradigm_. A simplified schematic would be\n",
    "```\n",
    "Root (Plur)? (Case)?\n",
    "```\n",
    "Plural is marked by _-k_, and accusative by _-t_. However, if the previous morpheme ends with a consonant (as is the case here), a link vowel is inserted before the _k_ or _t_. Which vowel gets inserted is decided by complicated _vowel harmony_ rules. The adjectives below all contain front vowels only, so the link vowel is **_e_**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "adjectives_1 = \"\"\"\n",
    "csendes       ! quiet\n",
    "egészséges    ! healthy\n",
    "idős          ! old\n",
    "kék           ! blue\n",
    "mély          ! deep\n",
    "öntelt        ! conceited\n",
    "szeles        ! windy\n",
    "terhes        ! pregnant; arduous\n",
    "zsémbes       ! shrewish\n",
    "\"\"\"\n",
    "\n",
    "grammar = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "compile_lexc(grammar, 'h1.fst')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Task H2.\n",
    "\n",
    "What we have now is a simple (lexical) FSA. In this task, we modify it to have a proper lexical FST that can parse (`apply_up`) surface forms to morphological features and vice versa (`apply_down`).\n",
    "\n",
    "- Run the words through HFST:\n",
    "  - Start a new docker bash shell by running `docker exec -it <container name or id> bash`\n",
    "  - Start HFST by typing `hfst-lookup --cascade=composition /nlp/hfst/hu.hfstol` into the shell\n",
    "  - Type the words in our FSA (don't forget plural / accusative, e.g. nagyok, finomat) into `hfst-lookup` one-by-one. See what features appear on the upper side (limit yourself to the correct parse, i.e. the one with `[/Adj]`).\n",
    "- Add the same features to our _lexc_ grammar:\n",
    "  - remember that you want to keep the surface form in the upper side as well, so e.g. `[/Pl]:ek` won't do. You must\n",
    "      - either repeat it twice: `ek[/Pl]:ek`\n",
    "      - or use two lexicons e.g. `Plur` and `PlurTag`, and have `ek` in the first and `[/Pl]:0` in the second\n",
    "  - all tags, such as `[/Pl]` must be defined in the `Multichar_Symbols` header:\n",
    "  \n",
    "```\n",
    "Multichar Symbols *Symb1* *Symb2* ...\n",
    "\n",
    "LEXICON Root\n",
    "...\n",
    "```\n",
    "Play around with `apply_up` and `apply_down`. Make sure you covered all tags in the HFST output. (Note: HFST tags color names as `[/Adj|col]`. You don't need to make this distinction in this exercise.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "grammar = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "compile_lexc(grammar, 'h2.fst')\n",
    "# apply_up('h2.fst', [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Task H2b*.\n",
    "\n",
    "Copy the `apply` functions and create a `hfst_apply` version of each, which calls _hfst_ instead of _foma_.. Note that _hfst-lookup_ does not support generation. You will probably need `communicate()` to implement function.\n",
    "\n",
    "_Important: do not start this exercise until you finish all foma-related ones!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Task H3.\n",
    "\n",
    "In the next few exercises, we are going to delve deeper into vowel harmony and techniques to handle it. For now, add the adjectives below to the grammar. In these words, back vowels dominate, so the link vowel for plural and accusative is **_a_**. Create `LEXICON` structures that mirror what you have for the front adjectives to handle the new words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "adjectives_2 = \"\"\"\n",
    "abszurd       ! absurd\n",
    "bájos         ! charming\n",
    "finom         ! delicious\n",
    "gyanús        ! suspicious\n",
    "okos          ! clever\n",
    "piros         ! red\n",
    "száraz        ! dry\n",
    "zord          ! grim\n",
    "\"\"\"\n",
    "\n",
    "grammar = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "compile_lexc(grammar, 'h3.fst')\n",
    "# apply_up('h3.fst', [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Task H4.\n",
    "\n",
    "The previous solution works, but implementing one distinction (_a_/_e_) required us to double the number of lexicons; this clearly doesn't scale. Here, we introduce a more flexible solution: **_flag diacritics_**.\n",
    "\n",
    "Flag diacritics are (`multichar`!) symbol with a few special properties:\n",
    "- they have the form `@COMMAND.FEATURE_NAME.FEATURE_VALUE@`, where command is\n",
    "    - `P`: set\n",
    "    - `R`: require\n",
    "    - `D`: XXX\n",
    "    - `U`: unification (first `P`, then `R`)\n",
    "- they never appears in the output\n",
    "- flag diacritics incur some performance overhead, but decrease the size of the FSTs\n",
    "\n",
    "Add flag diacritics to your grammar. You will want to keep the two adjective types in separate lexicons, e.g.\n",
    "```\n",
    "LEXICON Root\n",
    "@U.HARM.FRONT@  AdjFront ;\n",
    "@U.HARM.BACK@   AdjBack ;\n",
    "```\n",
    "However, the two plural / accusative lexicons can be merged, like so:\n",
    "```\n",
    "LEXICON Plur\n",
    "@U.HARM.FRONT@ek  PlurTag ;\n",
    "@U.HARM.BACK@ak   PlurTag ;\n",
    "```\n",
    "Compile your grammar to see that the network became smaller. Check and see if the new FST accepts the same language as the old one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "grammar = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "compile_lexc(grammar, 'h4.fst')\n",
    "# apply_up('h4.fst', [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Task H5.\n",
    "\n",
    "We round up the exercise by adding adjective comparison. Incorporate the following rules into your grammar:\n",
    "- _Comparative_ forms are marked by **_-bb_**, which takes a link vowel similarly to plural\n",
    "- The _superlative_ form is marked by the **_leg-_** prefix and **_-bb_**, i.e. a circumfix\n",
    "- The _exaggerated_ form is the same as the superlative, with any number of **_leges_** coming before _leg_\n",
    "\n",
    "The full simplified paradigm thus becomes:\n",
    "```\n",
    "((leges)* leg)? Root (-bb)? (Plur)? (Case)?\n",
    "```\n",
    "\n",
    "Again, the circumfix is best handled with flag diacritics. However, the `U` command probably won't work because its main use is for agreement. Try to implement an `if-else` structure with the other commands!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "grammar = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "compile_lexc(grammar, 'h5.fst')\n",
    "# apply_up('h5.fst', [])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
