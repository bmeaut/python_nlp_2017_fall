{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 10. Syntax — Lab exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Introduction\n",
    "\n",
    "In this lab, we are going to use the [Python Natural Language Toolkit](http://www.nltk.org/) (`nltk`). It has an API that allows you to create, read, and parse with Context-free Grammars (CFG), as well as to convert parse trees to Chomsky Normal Form (CNF) and back and to display or pretty print them.\n",
    "\n",
    "During the first few exercises, we are going to acquint ourselves with nltk using a toy grammar. In the second part, you will be asked to implement the CKY algorithm and test it on a real world treebank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Infrastructure\n",
    "\n",
    "For today's exercises, you will need the docker image again. Provided you have already downloaded it last time, you can start it by:\n",
    "\n",
    "- `docker ps -a`: lists all the containers you have created. Pick the one you used last time (with any luck, there is only one)\n",
    "- `docker start <container id>`\n",
    "- `docker exec -it <container id> bash`\n",
    "\n",
    "In order to be able to run today's exercises, you will have to install some system- and Python packages as well:\n",
    "\n",
    "```bash\n",
    "apt-get install python3-tk\n",
    "pip install graphviz\n",
    "```\n",
    "\n",
    "When that's done, update your git repository:\n",
    "\n",
    "```bash\n",
    "cd /nlp/python_nlp_2017_fall/\n",
    "git pull\n",
    "```\n",
    "\n",
    "And start the notebook:\n",
    "```\n",
    "jupyter notebook --port=9999 --ip=0.0.0.0 --no-browser --allow-root\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Boilerplate\n",
    "\n",
    "The following code imports the packages we are going to use. It also defines a function that draws the parse trees with the [`Graphviz`](http://www.graphviz.org/) library. `nltk` _can_ display the trees, but it depends on Tcl, which doesn't work on a headless (GUI-less) system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import graphviz\n",
    "import nltk\n",
    "from nltk import Nonterminal\n",
    "from nltk.parse.generate import generate\n",
    "from nltk.tree import Tree\n",
    "\n",
    "def does_tcl_work():\n",
    "    \"\"\"Checks if Tcl is installed and works (e.g. it won't on a headless server).\"\"\"\n",
    "    tree = nltk.tree.Tree('test', [])\n",
    "    try:\n",
    "        tree._repr_png_()\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def draw_tree(tree):\n",
    "    \"\"\"Draws an NLTK parse tree via Graphviz.\"\"\"\n",
    "    def draw_tree_rec(curr_root, graph, last_node):\n",
    "        node_id = str(int(last_node) + 1)\n",
    "        for child in curr_root:\n",
    "            if isinstance(child, nltk.tree.Tree):\n",
    "                graph.node(node_id, child.label(), penwidth='0')\n",
    "                graph.edge(last_node, node_id, color='darkslategray3', style='bold')\n",
    "                node_id = draw_tree_rec(child, graph, node_id)\n",
    "            else:\n",
    "                graph.node(node_id, child, penwidth='0')\n",
    "                graph.edge(last_node, node_id, color='darkslategray3', style='bold')\n",
    "        return str(int(node_id) + 1)\n",
    "    \n",
    "    graph = graphviz.Graph()\n",
    "    graph.graph_attr['ranksep'] = '0.2'\n",
    "    graph.node('0', tree.label(), penwidth='0')\n",
    "    draw_tree_rec(tree, graph, '0')\n",
    "    return graph._repr_svg_()\n",
    "\n",
    "# Use Graphviz to draw the tree if the Tcl backend of nltk doesn't work\n",
    "if not does_tcl_work():\n",
    "    svg_formatter = get_ipython().display_formatter.formatters['image/svg+xml']\n",
    "    svg_formatter.for_type(nltk.tree.Tree, draw_tree)\n",
    "    # Delete the nltk drawing function, just to be sure\n",
    "    delattr(Tree, '_repr_png_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Disclaimer\n",
    "\n",
    "NLTK is not the only NLP library for Python. [spaCy] is \"industrial-strength\" library which, like NLTK, implements various NLP tools for multiple languages. However, it also supports neural network models (on the GPU as well) and it integrates word vectors. A comparison is [availabe here](https://spacy.io/usage/facts-figures). We teach NLTK in this course because\n",
    "1. it lends itself better to education and experimentation\n",
    "1. of [certain](https://www.usatoday.com/story/life/2017/11/07/kevin-spacey-scandal-complete-list-13-accusers/835739001/) [scandals](http://index.hu/kultur/cinematrix/2017/11/03/kevin_spacey_karrierjenek_igencsak_lottek/)\n",
    "\n",
    "However, if you are doing serious NLP work, you should also consider spaCy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 1. Get to know nltk\n",
    "\n",
    "In this exercise, we are using the toy grammar from the lecture with a little modification so that it can handle ditransitives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# fromstring() returns a CFG instance from a string\n",
    "# Observe the two ways one can specify alternations in the grammar\n",
    "# and how terminal symbols are specified\n",
    "toy_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "NP -> Pronoun | ProperNoun | Det Nominal\n",
    "Nominal -> Nominal Noun\n",
    "Nominal -> Noun\n",
    "VP -> Verb | Verb PP | Verb NP | Verb NP PP | Verb NP NP | Verb NP NP PP\n",
    "PP -> Preposition NP\n",
    "Pronoun -> 'he' | 'she' | 'him' | 'her'\n",
    "ProperNoun -> 'John' | 'Mary' | 'Fido'\n",
    "Det -> 'a' | 'an' | 'the'\n",
    "Noun -> 'flower' | 'bone' | 'necklace' | 'dream' | 'hole' | 'café' | 'house' | 'bed'\n",
    "Verb -> 'loves' | 'gives' | 'gave' | 'sleeps' | 'digs' | 'dag' | 'ate'\n",
    "Preposition -> 'in' | 'on' | 'behind'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Now for some properties:\n",
    "\n",
    "print('Max RHS length:', toy_grammar.max_len())\n",
    "print('The start symbol is', toy_grammar.start())\n",
    "print('Is it in CNF:', toy_grammar.is_chomsky_normal_form())\n",
    "print('Is this a lexical grammar:', toy_grammar.is_lexical())\n",
    "print('All productions:', toy_grammar.productions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Let's generate a few sentences\n",
    "for sentence in generate(toy_grammar, n=10):\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Unfortunately, `generate()` only generates the sentences in order. Also, it can run into problems with recursive grammars. Here is a version that generates random sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from itertools import count\n",
    "\n",
    "def generate_sample(grammar, start=None):\n",
    "    \"\"\"Generates a single sentence randomly.\"\"\"\n",
    "    gen = [start or grammar.start()]\n",
    "    curr_p = 0\n",
    "    while curr_p < len(gen):\n",
    "        production = random.choice(grammar.productions(lhs=gen[curr_p]))\n",
    "        if production.is_lexical():\n",
    "            gen[curr_p] = production.rhs()[0]\n",
    "            curr_p += 1\n",
    "        else:\n",
    "            gen = gen[:curr_p] + list(production.rhs()) + gen[curr_p + 1:]\n",
    "    return ' '.join(gen)\n",
    "\n",
    "def generate_random(grammar, start=None, n=None):\n",
    "    \"\"\"Generates sentences randomly.\"\"\"\n",
    "    for i in count(0):\n",
    "        yield generate_sample(grammar, start)\n",
    "        if i == n:\n",
    "            break\n",
    "\n",
    "for sentence in generate_random(toy_grammar, n=10):\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Sentences can also be parsed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "toy_parser = nltk.ChartParser(toy_grammar)\n",
    "# the split() part is important\n",
    "for tree in toy_parser.parse('John gave Mary a flower in the café'.split()):\n",
    "    display(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The parse returns an iterator of `nltk.tree.Tree` objects. This class has some useful functions, such as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Converts the tree to CNF\n",
    "tree.chomsky_normal_form()\n",
    "display(tree)\n",
    "# Let's convert it back...\n",
    "tree.un_chomsky_normal_form()\n",
    "print('The tree has', len(tree), 'children.')\n",
    "print('The first child is another tree:', tree[0])\n",
    "print('All nonterminals are Trees. They have labels:', tree[1].label())\n",
    "print('Terminals are just strings:', tree[0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Note that in `nltk`, one can convert a `Tree` to CNF, but not the whole grammar. `nltk` has some strange design choices - the other being their reliance on Tcl. If you run this notebook on your own machine, a nifty grammar editing tool will pop up if you run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nltk.app.rdparser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. Arithmetics\n",
    "\n",
    "#### 2.1 Basics\n",
    "Model the four elementary mathematical operations, namely `+`, `-`, `*` and `/`. Your tasks is to validate mathematical expressions that use them. Specifically:\n",
    "- single-digit numbers are valid expressions\n",
    "- if `expr1` and `expr2` are valid expressions, these are also valid:\n",
    "  - `expr1 + expr2`\n",
    "  - `expr1 - expr2`\n",
    "  - `expr1 * expr2`\n",
    "  - `expr1 / expr2`\n",
    "  - `(expr1)`\n",
    "  \n",
    "Try to solve it with as few nonterminals as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "agr = nltk.CFG.fromstring(\"\"\"\n",
    "\"\"\")\n",
    "aparser = nltk.ChartParser(agr)\n",
    "\n",
    "# Test\n",
    "for tree in aparser.parse('1 - 2 / ( 3 - 4 )'.split()):\n",
    "    display(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 2.2 Precedence\n",
    "\n",
    "If you implemented the previous task with a single nonterminal, you will see that the grammar is undeterministic, and some parses do not reflect the precedence of mathematical operators. Fix the grammar so that it does!\n",
    "\n",
    "Hints:\n",
    "- `+` and `-` should be higher up the tree than `*` and `/`\n",
    "- you will need at least 3 nonterminals\n",
    "- allow chaining of the same operator types, e.g. `1 + 2 - 3`. One of the nonterminals in the toy grammar above does something similar\n",
    "- do not worry about unit productions, but don't create a unit recursion cycle (e.g. `A -> B -> C -> A`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "\n",
    "# Test\n",
    "for tree in aparser.parse('1 - 2 / ( 3 - 4 )'.split()):\n",
    "    display(tree)\n",
    "assert len(list(aparser.parse('1 - 2 + 3 / ( 4 - 5 )'.split()))) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 2.3 CNF\n",
    "\n",
    "Parse an expression and convert the resulting tree into CNF. If you succeed, congratulations, you can skip this exercise.\n",
    "\n",
    "However, most likely the function will throw an exception. This is because the NLTK algorithm cannot cope with rules that mix nonterminals and terminals in certain ways (e.g. `A -> B '+' C`). Fix your grammar by introducing a POS-like nonterminal (e.g. `add` for `+`) into each such rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "\n",
    "# Test\n",
    "tree = list(aparser.parse('1 - 2 / ( 3 - 4 )'.split()))[0]\n",
    "tree.chomsky_normal_form()\n",
    "display(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 2.4 Evaluation*\n",
    "\n",
    "Compute the value of the expression. Implement a recursive function that traverses the tree and returns an interger.\n",
    "\n",
    "Note: if you implemented this function well, but get an `AssertionError` from the last line, it means that your grammar is probably right associative. Look at the (non-CNF) tree to confirm this. If so, make it left associative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def evaluate_tree(tree):\n",
    "    \"\"\"Returns the value of the expression represented by tree.\"\"\"\n",
    "    pass\n",
    "\n",
    "# Test\n",
    "assert evaluate_tree(next(aparser.parse('1+2'))) == 3\n",
    "assert evaluate_tree(next(aparser.parse('1+2*3'))) == 7\n",
    "assert evaluate_tree(next(aparser.parse('3/(2-3)-4/2-5'))) == -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3. CKY\n",
    "\n",
    "Up until now, we used NLTK's `ChartParser` to parse our grammar. In this exercise, we will replace it with our own implementation of CKY."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 3.1 The parser class\n",
    "\n",
    "First, create the `CKYParser` class. Imitate the interface of `ChartParser`. You don't need to look up the API: support only the functions we used thus far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class CKYParser:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 3.2 Implement `parse()`\n",
    "\n",
    "Implement the `parse()` method. You don't need to worry about the backpointers for now; just treat the cells of the matrix as a piece of paper and write strings to them. The functions should just return `True` if the sentence is grammatical and `False` if it isn't.\n",
    "\n",
    "Hints:\n",
    "- the easiest format for the matrix is probably a 2D `numpy` array with a `list` in each cell (we might have multiple candidates in a cell). Use `dtype=object`. Don't forget to initialize it.\n",
    "- the `display()` method works on arrays and is a useful tool for debugging\n",
    "- in 2D `numpy` arrays, rows are numbered from top to bottom. That takes care of the cell indexing part, because a cell represents the words `sentence[row:col+1]`.\n",
    "- Implement just the main diagonal (lexical rules) first.\n",
    "- Use the `grammar.productions()` function to get the list of production rules. To see how to use it, refer to\n",
    "  - the `generate_sample` function above\n",
    "  - `help(grammar.productions)`\n",
    "- Note that in the production rules returned by `grammar.productions()`, terminals will be strings, and nonterminals instances of the `Nonterminal` object. You can get the actual symbol out of the latter with the `symbol()` method.\n",
    "\n",
    "Use the CNF grammar below for development and the example sentence for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP | ProperNoun VP | NP Verb | ProperNoun Verb\n",
    "NP -> Det Nominal | Det Noun\n",
    "Nominal -> Nominal Noun | Noun Noun\n",
    "VP -> Verb NP | Verb ProperNoun\n",
    "Det -> 'the'\n",
    "Noun -> 'dog' | 'bit'\n",
    "ProperNoun -> 'John'\n",
    "Verb -> 'bit'\n",
    "\"\"\")\n",
    "\n",
    "parser = CKYParser(grammar)\n",
    "print('Sentence is grammatical:', parser.parse('the dog bit John'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 3.3 The full monty\n",
    "\n",
    "Modify `parse()` so that it returns the parse tree. In the original CKY algorithm, each nonterminal maintains backpointers to its children. Instead, we will build the `Tree` object directly (which is little more that a label and a list of backpointers, really).\n",
    "\n",
    "There are two things you should do here:\n",
    "1. When filling a cell: instead of adding the name of the nonterminal to the list in the cell, add a `Tree` with the name as label and the right children. The constructor's signature is `Tree(node, children)`, where the latter is a `list`.\n",
    "2. Change your method to be a _generator_: yield all `Tree`s from the top right cell whose label is `S`.\n",
    "\n",
    "Don't forget that `Tree.label()`s are strings, so if you want to look for them in `grammar.productions()`, enclose them into a `Nonterminal` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Test\n",
    "parser = CKYParser(grammar)\n",
    "for tree in parser.parse('the dog bit John'.split()):\n",
    "    display(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 4. Treebanks\n",
    "\n",
    "NLTK also contains corpora. Amongst others, it contains about 10% of the Penn TreeBank (PTB)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 4.1 Download\n",
    "\n",
    "Download the corpus with the `nltk.download()` tool. It is under Corpora and is called `treebank`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 4.2 Corpus statistics\n",
    "\n",
    "The functions below can be used to get the file ids, words, sentences, parse trees from the treebank.\n",
    "\n",
    "Using them, get the following following corpus statistics:\n",
    "- the number of sentences\n",
    "- number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank\n",
    "\n",
    "# PTB file ids\n",
    "print('Ids:', treebank.fileids())\n",
    "\n",
    "# Words in one of the files\n",
    "print('Words:', treebank.words('wsj_0003.mrg'))\n",
    "\n",
    "# Word - POS-tag pairs\n",
    "print('Tagged words:', treebank.tagged_words('wsj_0003.mrg'))\n",
    "\n",
    "display(treebank.parsed_sents('wsj_0003.mrg')[0])\n",
    "\n",
    "# Your solution here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
